{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sio.loadmat(\"mnist_all.mat\")\n",
    "train0= tmp['train0']\n",
    "train1= tmp['train1']\n",
    "test0= tmp['test0']\n",
    "test1= tmp['test1']\n",
    "\n",
    "xtrain= np.vstack((train0, train1))\n",
    "ytrain=np.hstack((np.zeros(train0.shape[0]), np.ones(train1.shape[0])))\n",
    "ytrain= np.asmatrix(ytrain)\n",
    "xtrain= xtrain.T\n",
    "xtest= np.vstack((test0, test1))\n",
    "ytest= np.hstack((np.zeros(test0.shape[0]), np.ones(test1.shape[0])))\n",
    "ytest= np.asmatrix(ytest)\n",
    "xtest= xtest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 12665)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 1.]]\n",
      "(784, 12665)\n",
      "(1, 12665)\n"
     ]
    }
   ],
   "source": [
    "train= np.vstack((xtrain, ytrain))\n",
    "train= train.T\n",
    "np.random.shuffle(train)\n",
    "train=train.T\n",
    "print(train.shape)\n",
    "print(train)\n",
    "xtrain= np.split(train, [-1])[0]\n",
    "ytrain=np.split(train, [-1])[1]\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 2115)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(784, 2115)\n",
      "(1, 2115)\n"
     ]
    }
   ],
   "source": [
    "test= np.vstack((xtest, ytest))\n",
    "test= test.T\n",
    "np.random.shuffle(test)\n",
    "test=test.T\n",
    "print(test.shape)\n",
    "print(test)\n",
    "xtest= np.split(test, [-1])[0]\n",
    "ytest=np.split(test, [-1])[1]\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "def initialize(num_neur, d):\n",
    "    H= num_neur\n",
    "    \n",
    "    num_layers= d+2\n",
    "    \n",
    "    layersize= [0]*(num_layers+1)\n",
    "    layersize[0]= 784\n",
    "    \n",
    "    params= {}\n",
    "    \n",
    "    for l in range(1, num_layers):\n",
    "        if l== num_layers-1:\n",
    "            layersize[l] =1\n",
    "        else:\n",
    "            layersize[l]= 50\n",
    "            \n",
    "        \n",
    "        params['W'+str(l)]= np.random.normal(0, \n",
    "                            math.sqrt(1/layersize[l-1]), \n",
    "                            (layersize[l], layersize[l-1]))\n",
    "\n",
    "        params['b'+str(l)]= np.zeros((layersize[l], 1))\n",
    "        \n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_deriv(x):\n",
    "    S= sigmoid(x)\n",
    "    dS= np.multiply(S,(1-S))\n",
    "    \n",
    "    return dS\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, params, num_layers):\n",
    "    \n",
    "    cache= {}\n",
    "\n",
    "    h= x\n",
    "    \n",
    "    for l in range(1, num_layers):\n",
    "        \n",
    "        h_prev= h\n",
    "        w= params['W'+str(l)]\n",
    "        b= params['b'+str(l)]\n",
    "        z= np.dot(w, h_prev)+b\n",
    "        h= sigmoid(z)\n",
    "        \n",
    "        cache['Z'+str(l)]= z\n",
    "        if l>1:\n",
    "            cache['H'+str(l-1)]= h\n",
    "        else:\n",
    "            cache['H'+str(l-1)]=x\n",
    "    f= h\n",
    "    \n",
    "    return f, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(f, y):\n",
    "    m= y.shape[1]\n",
    "    \n",
    "    log= np.multiply(np.log(f), y)+np.multiply((1-y), np.log(1-f))\n",
    "    \n",
    "    loss= -np.sum(log)/m\n",
    "        \n",
    "    return np.squeeze(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backwards propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwards(f, y, params, cache, num_layers):\n",
    "    grade= {}\n",
    "    \n",
    "    m= f.shape[1]\n",
    "    y= y.reshape(f.shape)\n",
    "    \n",
    "    df= -(np.divide(y, f)-np.divide(1-y, 1-f))\n",
    "    dH_prev= df\n",
    "    \n",
    "    for i in reversed(range(1, num_layers)):\n",
    "        dH_cur= dH_prev\n",
    "        \n",
    "        w_cur= params['W'+str(i)]\n",
    "        z_cur= cache['Z'+str(i)]\n",
    "        h_prev= cache['H'+str(i-1)]\n",
    "        \n",
    "        dz, dw_cur, db_cur= reverse(dH_cur, z_cur, h_prev, w_cur)\n",
    "         \n",
    "        dH_prev= np.dot(w_cur.T, dz)\n",
    "        \n",
    "        grade[\"dW\"+str(i)]= dw_cur\n",
    "        grade[\"db\"+str(i)]= db_cur\n",
    "        \n",
    "        \n",
    "    return grade\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(dH, z, h_prev, w):\n",
    "    dZ= np.multiply(dH, sig_deriv(z))\n",
    "    m= h_prev.shape[1]\n",
    "    \n",
    "    dw= np.dot(dZ, h_prev.T)/m\n",
    "    db= np.sum(dZ, axis=1)/m\n",
    "    dH_prev= np.dot(w.T, dZ)\n",
    "    \n",
    "    return dZ, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params, grade, a, num_layers):\n",
    "    \n",
    "    for i in range(1, num_layers):\n",
    "        params[\"W\"+str(i)]= params[\"W\"+str(i)]-a*grade[\"dW\"+str(i)]\n",
    "        params[\"b\"+str(i)]= params[\"b\"+str(i)]-a*grade[\"db\"+str(i)]\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNtrain(x, y, train, num_neur, d, learnrate= 0.0075, num_iter= 10000):\n",
    "    loss=[]\n",
    "    \n",
    "    params = initialize(num_neur, d)\n",
    "    num_layers= d+2\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        batch= train[:,[np.random.choice(train.shape[1], 100, replace=False)]]\n",
    "        batch= np.squeeze(batch)\n",
    "        xnew= np.split(train, [-1])[0]\n",
    "        ynew=np.split(train, [-1])[1]\n",
    "        \n",
    "        f, cache= forward(xnew, params, num_layers)\n",
    "        \n",
    "        lossoniter= loss_func(f, ynew)\n",
    "        \n",
    "        grade = backwards(f, ynew, params, cache, num_layers)\n",
    "        params =update(params, grade, learnrate, num_layers)\n",
    "        \n",
    "        if i%500==0:\n",
    "            print(\"Loss after iteration %i: %f\" %(i,lossoniter))\n",
    "            \n",
    "        loss.append(lossoniter)\n",
    "        \n",
    "    f, cache= forward(x, params, num_layers)\n",
    "    lossfinal= loss_func(f, y)\n",
    "    print(\"final loss= \"+ str(lossfinal))\n",
    "    \n",
    "    plt.plot(np.squeeze(loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "    \n",
    "    return params, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.682802\n",
      "Loss after iteration 500: 0.473610\n",
      "Loss after iteration 1000: 0.461222\n",
      "Loss after iteration 1500: 0.445484\n",
      "Loss after iteration 2000: 0.413127\n",
      "Loss after iteration 2500: 0.379691\n",
      "Loss after iteration 3000: 0.346468\n",
      "Loss after iteration 3500: 0.303171\n",
      "Loss after iteration 4000: 0.264147\n",
      "Loss after iteration 4500: 0.234374\n",
      "Loss after iteration 5000: 0.203936\n",
      "Loss after iteration 5500: 0.178610\n",
      "Loss after iteration 6000: 0.155054\n",
      "Loss after iteration 6500: 0.135874\n",
      "Loss after iteration 7000: 0.119463\n",
      "Loss after iteration 7500: 0.105321\n",
      "Loss after iteration 8000: 0.093116\n",
      "Loss after iteration 8500: 0.082174\n",
      "Loss after iteration 9000: 0.073516\n",
      "Loss after iteration 9500: 0.066023\n",
      "final loss= 0.05936027064030787\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOXd9/HPL5OE7IQsEAhLggYRUBYjICDuit4K2loVrVurtLZoi2299bG979bn6X13sVZbaS11qbYqtS4UrRV3EJQl7GsghC1sCQFCWAIJuZ4/5pCOaYAIOUwm832/XvPKnHOumfmdHMh3zrnOuY455xAREQGICXcBIiLSeigURESkgUJBREQaKBRERKSBQkFERBooFEREpIFCQUREGigURESkgUJBREQaxIa7gC8qKyvL5eXlhbsMEZGIMn/+/B3OuezjtfM1FMxsFPAEEACeds79rNHyXwMXeZNJQEfnXPqx3jMvL4+ioiI/yhURabPMbENz2vkWCmYWACYClwFlwDwzm+qcW3GkjXNuQkj7e4GBftUjIiLH52efwmCgxDlX6pw7BEwGxhyj/VjgZR/rERGR4/AzFHKBTSHTZd68f2NmPYB84EMf6xERkePwMxSsiXlHG6f7JuBV59zhJt/IbJyZFZlZUUVFRYsVKCIin+dnKJQB3UKmuwJbjtL2Jo5x6Mg5N8k5V+icK8zOPm7nuYiInCA/Q2EeUGBm+WYWT/AP/9TGjczsDKAD8JmPtYiISDP4FgrOuTpgPDANWAm84pxbbmaPmNnokKZjgclOt4ATEQk7X69TcM69DbzdaN5/NZr+sZ81HDFv/U6mF1cw4bJeBGKa6u4QEZGoGeZi0cbdPPlRCQdqm+zLFhERoigUEuIDABw4pFAQETmaqAmFxLhgKNRoT0FE5KiiLhR0+EhE5OiiJxTig6uqw0ciIkcXPaEQFzzRSnsKIiJHFz2hEK/DRyIixxM9oXCko1mHj0REjirqQkF7CiIiRxc1oZBwpKNZoSAiclRREwoNewo6fCQiclRREwoJCgURkeOKmlCIC8QQFzAdPhIROYaoCQUIHkLarz0FEZGjiqpQSE2Io7qmLtxliIi0WlEVCmmJceypqQ13GSIirVZ0hUJCLFUHFAoiIkcTXaGQGMcehYKIyFFFVyioT0FE5JiiKxQSY7WnICJyDNEVCglxVB+s43C9C3cpIiKtUnSFQmIcAHt1CElEpEnRFQoJwRvt6LRUEZGm+RoKZjbKzIrNrMTMHjxKmxvMbIWZLTezl/ysJz0pHoBd+w/5+TEiIhEr1q83NrMAMBG4DCgD5pnZVOfcipA2BcBDwHDn3C4z6+hXPQCZKcFQqNynUBARaYqfewqDgRLnXKlz7hAwGRjTqM3dwETn3C4A51y5j/WQldwOgB3VB/38GBGRiOVnKOQCm0Kmy7x5oXoBvcxslpnNNrNRTb2RmY0zsyIzK6qoqDjhgrSnICJybH6GgjUxr/G5oLFAAXAhMBZ42szS/+1Fzk1yzhU65wqzs7NPuKCk+AAJcTFU7tWegohIU/wMhTKgW8h0V2BLE23+7pyrdc6tA4oJhoQvzIzM5HZU7tWegohIU/wMhXlAgZnlm1k8cBMwtVGbKcBFAGaWRfBwUqmPNZGVEk+F9hRERJrkWyg45+qA8cA0YCXwinNuuZk9YmajvWbTgEozWwF8BPzAOVfpV00AWSnaUxARORrfTkkFcM69DbzdaN5/hTx3wP3e45TITIln2ZaqU/VxIiIRJaquaAbI9PYU6jX+kYjIv4m6UMhOaUddvdNVzSIiTYi6UMhpnwDAtj01Ya5ERKT1ibpQ6JQWDIXtCgURkX8TdaHQsKdQpdNSRUQai7pQ6JjaDjMdPhIRaUrUhUJcIIbM5HZsr1IoiIg0FnWhANC5fYL2FEREmhCVodApLUEdzSIiTYjKUMhp3057CiIiTYjKUOjWIYnd+2upOqB7NYuIhIrKUOiZnQJAacXeMFciItK6RGkoJAOwtmJfmCsREWldojIUumckERtj2lMQEWkkKkMhLhBD98wkSrWnICLyOVEZCgBndEplxdY94S5DRKRVidpQGNg9nY0797NDt+YUEWkQxaHQAYAFG3aFuRIRkdYjakPhrNz2JMYFmFmyI9yliIi0GlEbCglxAYafnsmHq8oJ3ipaRESiNhQALurdkbJdByjeXh3uUkREWoWoDoUr+uYQFzD+VlQW7lJERFqFqA6FrJR2XN4nh9cXlFFTezjc5YiIhJ2voWBmo8ys2MxKzOzBJpbfYWYVZrbIe9zlZz1NuWVod3btr+WNhZtP9UeLiLQ6voWCmQWAicCVQB9grJn1aaLpX51zA7zH037VczTn9cykX24af/yklPp6dTiLSHTzc09hMFDinCt1zh0CJgNjfPy8E2JmjBt5GqUV+3h/5fZwlyMiElZ+hkIusClkusyb19iXzWyJmb1qZt2aeiMzG2dmRWZWVFFR0eKFXtUvh64dEpk0o7TF31tEJJL4GQrWxLzGx2feBPKcc2cD7wPPN/VGzrlJzrlC51xhdnZ2C5cJsYEYvj4in6INu5i+uuVDR0QkUvgZCmVA6Df/rsCW0AbOuUrn3JHBh/4InONjPcc0dnB3emYn8/AbS9m9/1C4yhARCSs/Q2EeUGBm+WYWD9wETA1tYGadQyZHAyt9rOeYEuIC/PL6/pTvOcidf5qnW3WKSFTyLRScc3XAeGAawT/2rzjnlpvZI2Y22mt2n5ktN7PFwH3AHX7V0xzn9OjAb8YOZNnmKm546jM27dwfznJERE45i7RxfwoLC11RUZGvnzGrZAf3/GU+gRhj4s2DGHZ6lq+fJyLiNzOb75wrPF67qL6i+WiGn57F1PEjyEppx63PzuW5Wes0aJ6IRAWFwlHkZSXzxreHc3HvjvzkzRX84NUlGgpDRNo8hcIxpLSL5Q9fPYf7Ling1fllfOWpz3hn2VYO1dWHuzQREV/EhruA1i4mxrj/sl706ZzKf09dzjf/soD0pDiGn57F8NOyGNQjndOyU4gLKF9FJPIpFJppVL/OXNYnhxlrKnhz0RZmrd3BP5ZsBSA+NobeOan07ZJGv9z2nJ2bTq+cFNrFBsJctYjIF6Ozj06Qc47SHftYtrmK5Vv2sHxL8Ofu/cHrG+ICRu+cNM7p0YGhPTMYnJ9JRnJ8mKsWkWjV3LOPFAotyDlH2a4DLCmrYunmKhZv2s3CTbuoqQ32QfTOSWVIfgZDe2YyOD+DzJR2Ya5YRKKFQqGVOFRXz9LNu5ldupPZpZUUrd/FAe8spr5d0risTycu69OJPp3TMGtquCgRkZOnUGilag/Xs6SsitmllXy4qpwFG3fhHORnJXPtgFyuHdiFHpnJ4S5TRNoYhUKEqKg+yPsrt/P3RZuZs24nzsGAbulcNzCXq8/urENMItIiFAoRaMvuA0xdvIUpCzezals1cQHjxnO7ce/FBXRKSwh3eSISwRQKEW7Vtj288NkG/la0iYTYAA9e1Zux53YnJkb9DiLyxWnsowjXOyeN/7nuLN6bcAH9ctvz8BvLGPvH2Rq5VUR8pVBo5fKyknnp7iH8/MtnsWLrHsZMnMWna3eEuywRaaMUChHAzLjx3O5MHT+CDklx3PL0HB56fSnbqmrCXZqItDEKhQiSn5XM1PEj+NrwfP5WtImRv/yIn7y5nMq9B4//YhGRZlBHc4TatHM/T35YwqsLykiMC/DNC3ry9RE9SYzXeEsi8u/U0dzGdctI4ufXn820745k2GmZPPruaq6dOIsNlfvCXZqIRDCFQoQ7vWMKk24r5PmvDWbbnhp1RIvISVEotBEX9Mpm6vjhZKW047Zn5vL8p+t1C1ER+cIUCm1Ij8xkXv/WMEb2yua/py7n2y8tYE9NbbjLEpEIolBoY9IS4nj6tkIevLI305Zv55rfzqS0Ym+4yxKRCOFrKJjZKDMrNrMSM3vwGO2uNzNnZsftGZfji4kxvnnBafx13FD21tTx5d9/yrz1O8NdlohEAN9CwcwCwETgSqAPMNbM+jTRLhW4D5jjVy3RqjAvg9fuGUZaYhxfeeozxr+0QHsNInJMfu4pDAZKnHOlzrlDwGRgTBPt/i/wC0CX5/ogLyuZt+4dwb0Xn84HK8u59LHpfP9vi9lYqTGUROTf+RkKucCmkOkyb14DMxsIdHPOveVjHVEvNSGO711+BjMeuIg7h+fz5uItXPyrj3no9SWU7VI4iMi/+BkKTY3x3HCOpJnFAL8GvnfcNzIbZ2ZFZlZUUVHRgiVGl+zUdvzo6j7MeOAivjq0B6/N38xFj37M/769kv2H6sJdnoi0An6GQhnQLWS6K7AlZDoV6Ad8bGbrgaHA1KY6m51zk5xzhc65wuzsbB9Ljg6d0hL48ei+fPyDC7luYC5/mFHKpb+aroveRKR5oWBm3zGzNAt6xswWmNnlx3nZPKDAzPLNLB64CZh6ZKFzrso5l+Wcy3PO5QGzgdHOOQ1sdIp0SU/kF9f359VvnkdCfIDbnpnLq/PLwl2WiIRRc/cUvuac2wNcDmQDdwI/O9YLnHN1wHhgGrASeMU5t9zMHjGz0SdRs7SwwrwMpnx7OEN7ZvL9vy3m2Znrwl2SiIRJbDPbHekfuAp4zjm32MyOe19I59zbwNuN5v3XUdpe2MxaxAdpCXE8c0ch33l5EY+8tYKqA7V899ICmrGZRaQNae6ewnwze5dgKEzzri2o968sCYd2sQGevHkg15/TlSc+WMNP3lxB3WFtZpFo0tw9ha8DA4BS59x+M8sgeAhJ2pjYQAy/+PLZtE+M45mZ61hctpvHbhhAflZyuEsTkVOguXsK5wHFzrndZvZV4IdAlX9lSTjFxBg/uroPvx07kLXle7nqiU94cc4GjboqEgWaGwq/B/abWX/gAWAD8IJvVUmrcE3/Lrw74QIK8zrw8BvLuP25eWzZfSDcZYmIj5obCnUu+DVxDPCEc+4JgtcZSBuX0z6B5+8czE9G96Vo/U4u//UMXp67UXsNIm1Uc0Oh2sweAm4F/uENdhfnX1nSmsTEGLcPy2Pad0dyVm57Hnp9Kbc+M5dNOzVEhkhb09xQuBE4SPB6hW0ExzD6pW9VSavULSOJF+8awv+7th8LN+5i1OMz+PPsDdTXa69BpK1oVih4QfAi0N7MrgZqnHPqU4hCMTHGV4f2YNqEkQzq0YEfTVnG3S8UUXVAd3gTaQuaO8zFDcBc4CvADcAcM7vez8KkdevaIYkXvhbsa5i+uoIxT86keFt1uMsSkZPU3MNHDwPnOudud87dRvBeCT/yryyJBGbBvobJ44ay79Bhrp04i1fmbVIntEgEa24oxDjnykOmK7/Aa6WNK8zL4B/3jqB/t/Y88NoSvvHn+VTuPRjuskTkBDT3D/s7ZjbNzO4wszuAf9BoTCOJbh3TEnjprqE8fNWZfFxcwRWPf8JHq8qP/0IRaVWa29H8A2AScDbQH5jknPtPPwuTyBMTY9w9sid/Hz+crJR47vzTPH44ZanGTxKJIM0d+wjn3GvAaz7WIm3EmZ3TmPLt4Tw6rZinZ67jUF09P//y2RpxVSQCHDMUzKyakFtohi4CnHMuzZeqJOIlxAX44dV9SGoXy28+WENBx1TuHtkz3GWJyHEcMxSccxrKQk7KhEsLWL2tmp+/s4pBPTpwTo8O4S5JRI5BZxCJr8yMn19/Nl3SE/nGn+dTtktDY4i0ZgoF8V37xDievaOQg3WHuev5IqprdPWzSGulUJBT4vSOqfz+lnNYU76Xe19eyMG6w+EuSUSaoFCQU2ZEQRY/vbYfHxdXcNfzGi9JpDVSKMgpddPg7jz6lf58traS0U/OZMWWPeEuSURCKBTklLv+nK5MHjeUmtrDfOn3s3htflm4SxIRj0JBwqIwL4O37j2f/l3T+d7fFjPhr4t0OEmkFfA1FMxslJkVm1mJmT3YxPJvmtlSM1tkZjPNrI+f9Ujrkp3ajhfvGsKES3sxdfEWrnx8Bp+W7Ah3WSJRzbdQ8G7ZORG4EugDjG3ij/5LzrmznHMDgF8Aj/lVj7ROsYEYvnNpAa/fM4yEuAA3Pz2H/317JbUaL0kkLPzcUxgMlDjnSp1zh4DJwJjQBs650F7GZJoeUkOiQP9u6fzjvvO5ZUh3/jCjlFv+OIeKag2/LXKq+RkKucCmkOkyb97nmNm3zWwtwT2F+3ysR1q5xPgAP73uLJ64aQBLN1dx+7Nz2XuwLtxliUQVP0OhqSEx/21PwDk30Tl3GvCfwA+bfCOzcWZWZGZFFRUVLVymtDZjBuTy1K3nULy9mruen8eBQ7rQTeRU8TMUyoBuIdNdgS3HaD8ZuLapBc65Sc65QudcYXZ2dguWKK3VBb2yeeyG/sxZt5MxE2eybHNVuEsSiQp+hsI8oMDM8s0sHrgJmBrawMwKQib/A1jjYz0SYcYMyOW5O85l9/5arp04iyc/XMPhenU7ifjJt1BwztUB44FpwErgFefccjN7xMxGe83Gm9lyM1sE3A/c7lc9EpkuPKMj704Yyah+OTz67mpu/MNnbNqpkVZF/GLORdY3r8LCQldUVBTuMiQMpizczI+mLMMBj4zpy3UDc3U3N5FmMrP5zrnC47XTFc0SMa4dmMvb3zmfMzuncv8rwauga2rVCS3SkhQKElG6ZSQxedx53H9ZL6Ys2sIdz81lj+7PINJiFAoScQIxxn2XFPD4jQMoWr+LG576jPI9NeEuS6RNUChIxLp2YC7P3nEuG3fu5/qnPmP9jn3hLkkk4ikUJKKN7JXNS3cPZU9NLVf/diZvLNQw3CInQ6EgEW9At3TeuncEZ3ZOZcJfF3PfywvZvf9QuMsSiUgKBWkTunYIdkB///Je/GPpVi59bDp/X7SZSDvlWiTcFArSZgRijPEXF/Dm+BHkdkjiO5MXcduzc9lQqb4GkeZSKEib06dLGq/fM4yfjO7Lwo27ufzXM/jdxyW6R4NIMygUpE0KxBi3D8vjvftHcuEZ2fzinWKu+e1MFmzcFe7SRFo1hYK0aZ3bJ/KHWwuZdOs57N5fy5d//yk/mrJMF7yJHIVCQaLC5X1zeP97F3D7eXn8Zc4GLv3VdN5eulUd0SKNKBQkaqS0i+XHo/sy5VvDyUppx7deXMBdzxdRtkujroocoVCQqNO/WzpTxw/nh/9xJp+ureSyx2bwxxml1KkjWkShINEpNhDDXef35L37R3LeaZn89O2VjH5yFos37Q53aSJhpVCQqNa1QxLP3F7I728ZxI69B7nud7P48dTlVKsjWqKUQkGinplx5Vmdef97F/DVoT14/rP1XPbYDKYt3xbu0kROOYWCiCctIY5HxvTjtXuGkZ4Uxzf+PJ+7Xyhiy+4D4S5N5JRRKIg0Mqh7B968dwQPXdmbT9ZUcNlj03l25jrq63X6qrR9CgWRJsQFYvjGBafx3oQLKMzL4JG3VvDNv8zXRW/S5ikURI6hW0YSf7rzXP7r6j58sKqcK349gxmrK8JdlohvFAoix2FmfG1EPq/fM4zkdrHc9uxcvv3iAl30Jm2SQkGkmfp7N/O5/7JefLBqO5f8ajqPv7+amtrD4S5NpMX4GgpmNsrMis2sxMwebGL5/Wa2wsyWmNkHZtbDz3pETlZCXID7Lingg+9dyKV9OvH4+2u45FfTmbp4izqipU3wLRTMLABMBK4E+gBjzaxPo2YLgULn3NnAq8Av/KpHpCXlpicy8eZBTB43lLTEOO57eSHX/W4Ws0srw12ayEnxc09hMFDinCt1zh0CJgNjQhs45z5yzh05MDsb6OpjPSItbmjPTN66dwSPfqU/5dUHuWnSbL7+p3ms2V4d7tJEToifoZALbAqZLvPmHc3XgX82tcDMxplZkZkVVVTozA9pXQIxxvXndOWj71/IA6POYO66nVzx+Aween0J5Xtqwl2eyBfiZyhYE/OaPOhqZl8FCoFfNrXcOTfJOVfonCvMzs5uwRJFWk5CXIBvXXg60x+4iNuH5fHq/DIu+OXHPDqtmKoDur5BIoOfoVAGdAuZ7gpsadzIzC4FHgZGO+cO+liPyCmRkRzPf1/Tl/fvv4CLz+zIkx+VcP7PP2TiRyXsO1gX7vJEjsn8uvOUmcUCq4FLgM3APOBm59zykDYDCXYwj3LOrWnO+xYWFrqioiIfKhbxx/ItVTz27mo+WFVOVko891x4OrcM6U5CXCDcpUkUMbP5zrnC47bz83aEZnYV8DgQAJ51zv3UzB4BipxzU83sfeAsYKv3ko3OudHHek+FgkSqBRt38at3i5lVUknn9gnce3EBXynsSlxAlwuJ/1pFKPhBoSCR7tO1O3h0WjELNu6me0YSEy4rYHT/XAIxTXXDibSM5oaCvqKInGLDTsvitXuG8ewdhaS0i2XCXxfzH7/5hPdXbCfSvqRJ26NQEAkDM+Pi3p14694R/HbsQA7W1XPXC0Vc/9RnzNEFcBJGCgWRMIqJMa7p34V3J4zkf647i7Jd+7lx0mzueG4uyzZXhbs8iULqUxBpRWpqD/P8p+v53cdrqTpQy+V9OvGdSwvo26V9uEuTCKeOZpEItqemludmrufpmaVU19RxRd9O3HeJwkFOnEJBpA2oOlDLc7PW8czMdVTX1HHpmR256/yeDMnPwExnK0nzKRRE2pAj4fDCZxvYue8QZ3dtz93n9+TKfjnE6joHaQaFgkgbVFN7mNcWlPH0J+tYt2MfuemJ3Dk8jxvP7UZqQly4y5NWTKEg0obV1zs+WFXOH2eUMnf9TpLjA3xpUFduPa8HvTqlhrs8aYUUCiJRYvGm3bzw2QbeXLKFQ3X1DMnP4NbzenBF3xwNoSENFAoiUWbnvkO8UrSJv8zeQNmuA3RMbcfYwd0ZO7g7Oe0Twl2ehJlCQSRKHa53fFxczp9nb+Dj4goCMcZFZ3TkhsKuXNS7o/YeolRzQyH2VBQjIqdOIMa45MxOXHJmJzZU7uOluRt5bf5m3l+5nayUeL40qCtfOacrBep7kCZoT0EkCtQermd6cQWvFG3iw1Xl1NU7BnZP54bCblx9dmeduRQFdPhIRJq0Y+9BpizczCtFm1i9fS8JcTFcemYnrh2Qy8he2cTH6vBSW6RQEJFjcs6xpKyKV+eX8Y+lW9m57xDpSXFcdVZnrh2QS2GPDsToHg9thkJBRJqt9nA9M9fsYMqizby7fDsHag+Tm57INf27MGZAF3rnpGpYjQinUBCRE7LvYB3vrdjOlEWb+WTNDg7XO/KzkhnVL4cr++VwVm57BUQEUiiIyEmr3HuQfy7bxjvLtvFZaSWH6x256Ylc2S+HK8/KYWA3HWKKFAoFEWlRu/Yd4r2V2/nn0q3MLNlB7WFHp7R2jOqbw+V9czg3L0Od1K2YQkFEfLOnppYPV5bz9tKtTF9dwcG6elLbxTKyVzaXnNmRC8/oSEZyfLjLlBAKBRE5JfYfqmNWSSUfrNzOB6vKqag+SIzBoO4dvIvoOlLQMUX9EGHWKkLBzEYBTwAB4Gnn3M8aLR8JPA6cDdzknHv1eO+pUBBpverrHcu2VPH+ynI+XLWdZZv3ANAtI5FLenfi/IIshvTMJKWdBlM41cIeCmYWAFYDlwFlwDxgrHNuRUibPCAN+D4wVaEg0rZsq6rhw1XlfLByO7PW7qCmtp7YGGNQ9w6cX5DFiIIszu6aTkCd1b5rDWMfDQZKnHOlXkGTgTFAQyg459Z7y+p9rENEwiSnfQI3D+nOzUO6U1N7mAUbdjFjzQ5mllTw2Pur+dV7q0lLiGXYacGAOL8gix6ZyeEuO6r5GQq5wKaQ6TJgiI+fJyKtWEJcgGGnZzHs9CygNzv3HWJWyQ4+WVPBzDU7eGf5NgBy0xMZ0jODofmZDO2ZSbeMRPVHnEJ+hkJTW/GEjlWZ2ThgHED37t1PpiYRaSUykuO5pn8XrunfBeccpTv2MXPNDuasq+Tj4gpeX7AZgC7tExjSM5OhPTMYkp9Jj8wkhYSP/AyFMqBbyHRXYMuJvJFzbhIwCYJ9Cidfmoi0JmbGadkpnJadwu3D8nDOUVK+l9mllcwu3cknayp4Y2EwJHLSEoJ7Ej0zGZKfQX5WskKiBfkZCvOAAjPLBzYDNwE3+/h5ItJGmBkFnVIp6JTKrecFQ2JtxV5ml+5kdmkln66t5O+Lgt8xs1LiKeyRwbn5GQzOy+DMzqnE6kZCJ8zvU1KvInjKaQB41jn3UzN7BChyzk01s3OBN4AOQA2wzTnX91jvqbOPROTI4aa563Yyb91O5q7fSdmuAwAkxwcY1KMDg/OCQTGgWzoJcYEwVxx+YT8l1S8KBRFpytaqA8xbv4t563Yyb/1OirdX4xzEBYw+XdrTt0ua92hP75zUqAsKhYKIRLWq/bUUbQjuRSzZVMXyLVXsqakDgrcsPT07hb5d0ujTJY1+ue3p0yWNtDZ8BzqFgohICOccZbsOsHxLFcu37GHZ5uDP8uqDDW1y0xPpnZNKr5xUeuekckZOKj2zUtrEQH+t4eI1EZFWw8zolpFEt4wkRvXr3DC/vLqG5Vv2sGLLHlZtq2b1tmqmr66grj74hTk2xuiZnUyvTkeCIo0zOqXStUNimxw2XKEgIlGtY2oCHc9I4KIzOjbMO1RXT+mOvRRvq6Z4WzWrt1ezaNNu3lqytaFNYlyAntnJDafSHnmen5VMYnzk9lcoFEREGomPjaF3Thq9c9I+N7+6ppY15XsbgqK0Yh8LNu7izSVbOHIk3gy6tE/ktI4pnJadTM/s4M/Ts1PITm3X6q+pUCiIiDRTakIcg7p3YFD3Dp+bX1N7mHU79rG2Yi9ry/dRumMvayv2Mm/dTg7UHm5olxQfoEdmMj0ykuiRlUReZjI9MpPokZlM57SEVnE4SqEgInKSEuICnNk5jTM7f37PwjnHtj01rC0PBsb6yn1sqNzPmvJqPlxVzqHD/xoLND42hu4ZSeRlJtE9I5m8rGBY5GUm0SU9kbhTdEGeQkFExCdmRuf2iXRun8iIgqzPLTtc79hadYANlftZX7mPjd7PDZX7mVkSHGb8iECMkZueyPcu78WYAbm+1qxQEBEJg0CM0bVDEl07JDH89M8HhnOOiuqDrG8Iin1s3HngiKqGAAAHYElEQVSArJR2vtelUBARaWXMjI5pCXRMS2BwfsYp/ezIvyJDRERajEJBREQaKBRERKSBQkFERBooFEREpIFCQUREGigURESkgUJBREQaRNxNdsysAthwgi/PAna0YDmRQOscHbTO0eFk1rmHcy77eI0iLhROhpkVNefOQ22J1jk6aJ2jw6lYZx0+EhGRBgoFERFpEG2hMCncBYSB1jk6aJ2jg+/rHFV9CiIicmzRtqcgIiLHEDWhYGajzKzYzErM7MFw13OizKybmX1kZivNbLmZfcebn2Fm75nZGu9nB2++mdlvvPVeYmaDQt7rdq/9GjO7PVzr1FxmFjCzhWb2ljedb2ZzvPr/ambx3vx23nSJtzwv5D0e8uYXm9kV4VmT5jGzdDN71cxWedv7vLa+nc1sgvfvepmZvWxmCW1tO5vZs2ZWbmbLQua12HY1s3PMbKn3mt+Y2Re78bNzrs0/gACwFugJxAOLgT7hrusE16UzMMh7ngqsBvoAvwAe9OY/CPzce34V8E/AgKHAHG9+BlDq/ezgPe8Q7vU7zrrfD7wEvOVNvwLc5D1/CrjHe/4t4Cnv+U3AX73nfbxt3w7I9/5NBMK9XsdY3+eBu7zn8UB6W97OQC6wDkgM2b53tLXtDIwEBgHLQua12HYF5gLnea/5J3DlF6ov3L+gU7QRzgOmhUw/BDwU7rpaaN3+DlwGFAOdvXmdgWLv+R+AsSHti73lY4E/hMz/XLvW9gC6Ah8AFwNvef/gdwCxjbcxMA04z3se67Wzxts9tF1rewBp3h9IazS/zW5nLxQ2eX/oYr3tfEVb3M5AXqNQaJHt6i1bFTL/c+2a84iWw0dH/rEdUebNi2je7vJAYA7QyTm3FcD72dFrdrR1j7TfyePAA8CRu5lnArudc3XedGj9DevmLa/y2kfSOvcEKoDnvENmT5tZMm14OzvnNgOPAhuBrQS323za9nY+oqW2a673vPH8ZouWUGjqmFpEn3ZlZinAa8B3nXN7jtW0iXnuGPNbHTO7Gih3zs0Pnd1EU3ecZRGzzgS/+Q4Cfu+cGwjsI3hY4Wgifp294+hjCB7y6QIkA1c20bQtbefj+aLreNLrHi2hUAZ0C5nuCmwJUy0nzcziCAbCi865173Z282ss7e8M1DuzT/aukfS72Q4MNrM1gOTCR5CehxIN7NYr01o/Q3r5i1vD+wksta5DChzzs3xpl8lGBJteTtfCqxzzlU452qB14FhtO3tfERLbdcy73nj+c0WLaEwDyjwzmKIJ9gpNTXMNZ0Q70yCZ4CVzrnHQhZNBY6cgXA7wb6GI/Nv885iGApUebun04DLzayD9w3tcm9eq+Oce8g519U5l0dw233onLsF+Ai43mvWeJ2P/C6u99o7b/5N3lkr+UABwU65Vsc5tw3YZGZneLMuAVbQhrczwcNGQ80syft3fmSd2+x2DtEi29VbVm1mQ73f4W0h79U84e5wOYUdO1cRPFNnLfBwuOs5ifUYQXB3cAmwyHtcRfBY6gfAGu9nhtfegIneei8FCkPe62tAife4M9zr1sz1v5B/nX3Uk+B/9hLgb0A7b36CN13iLe8Z8vqHvd9FMV/wrIwwrOsAoMjb1lMInmXSprcz8BNgFbAM+DPBM4ja1HYGXibYZ1JL8Jv911tyuwKF3u9vLfAkjU5WON5DVzSLiEiDaDl8JCIizaBQEBGRBgoFERFpoFAQEZEGCgUREWmgUJCoY2afej/zzOzmFn7v/9PUZ4lECp2SKlHLzC4Evu+cu/oLvCbgnDt8jOV7nXMpLVGfSDhoT0Gijpnt9Z7+DDjfzBZ54/gHzOyXZjbPG7v+G177Cy14D4uXCF5AhJlNMbP53tj/47x5PwMSvfd7MfSzvCtSf2nB+wQsNbMbQ977Y/vXfRNePDL+vZn9zMxWeLU8eip/RxK9Yo/fRKTNepCQPQXvj3uVc+5cM2sHzDKzd722g4F+zrl13vTXnHM7zSwRmGdmrznnHjSz8c65AU181pcIXqHcH8jyXjPDWzYQ6EtwjJpZwHAzWwFcB/R2zjkzS2/xtRdpgvYURP7lcoLjzCwiOBx5JsFxcwDmhgQCwH1mthiYTXBgsgKObQTwsnPusHNuOzAdODfkvcucc/UEhy3JA/YANcDTZvYlYP9Jr51IMygURP7FgHudcwO8R75z7siewr6GRsG+iEsJ3rilP7CQ4Dg8x3vvozkY8vwwwRvK1BHcO3kNuBZ45wuticgJUihINKsmeEvTI6YB93hDk2Nmvbwb2zTWHtjlnNtvZr0J3ibxiNojr29kBnCj12+RTfCWjEcdudO7X0Z759zbwHcJHnoS8Z36FCSaLQHqvMNAfwKeIHjoZoHX2VtB8Ft6Y+8A3zSzJQRH4ZwdsmwSsMTMFrjg8N5HvEHwVpKLCY5y+4BzbpsXKk1JBf5uZgkE9zImnNgqinwxOiVVREQa6PCRiIg0UCiIiEgDhYKIiDRQKIiISAOFgoiINFAoiIhIA4WCiIg0UCiIiEiD/w+ssnmb1e1fzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainedparams, loss= NNtrain(xtrain, ytrain, train, 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05785867890765255\n"
     ]
    }
   ],
   "source": [
    "# Calculate Loss for test set\n",
    "f, cache= forward(xtest, trainedparams, 4)\n",
    "testloss= loss_func(f, ytest)\n",
    "print(testloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c: \n",
    "How does dW1 change as d gets bigger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2930179752687936, 0.6233535900346424, 0.1491313139600949, 0.03316026205293577]\n"
     ]
    }
   ],
   "source": [
    "dw1= []\n",
    "for i in range(4):\n",
    "    params= initialize(50, i+1)\n",
    "    f, cache= forward(xtrain, params, i+3)\n",
    "    grade = backwards(f, ytrain, params, cache, i+3)\n",
    "    dw1.append(np.linalg.norm(grade[\"dW\"+str(1)]))\n",
    "    \n",
    "print(dw1)\n",
    "\n",
    "# as you can see, the gradient is clearly decreasing\n",
    "# as the number of hidden layers increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
